---
title: "CS3200 Final Proj - Duncan Muir"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(XML)
library(xml2)
library(rvest)

```

```{r}
scrapeLinks <- function(url){
  options(timeout= 4000000)
  # Create an html document from the url
  webpage <- xml2::read_html(url)
  # Extract the URLs
  url_ <- webpage %>%
    html_nodes("a") %>%
    html_attr("href")
  # Extract the link text
  link_ <- webpage %>%
    html_nodes("a") %>%
    html_text()
  return(data_frame(link = link_, url = url_))
}

mtproj_url <- "https://www.mountainproject.com/"
alabama <- "https://www.mountainproject.com/area/105905173/alabama"
shiprock <- "https://www.mountainproject.com/area/106248455/bankhead-forestship-rock"
hp40 <- "https://www.mountainproject.com/area/106094862/horse-pens-40"

links <- scrapeLinks(mtproj_url)


unique(html_attr(html_nodes(read_html(mtproj_url), 'strong .float-xs-left'), 'href'))


get_subarea_urls <- function(x) {
  if(grepl("Areas",html_text(html_node(read_html(x), '#climb-area-page h3'))))
    return(sapply(as.character(html_attr(html_nodes(read_html(x), '.lef-nav-row a'), 'href')), get_subarea_urls))
  else 
    return(get_boulder_urls(x))
}

get_boulder_urls <- function(x) {
  links <-  html_attr(html_nodes(read_html(x), "#left-nav-route-table a"), 'href')
  return(links)
}


system.time(alabama_climbs <- sapply(alabama, get_subarea_urls))
all_alabama_routes <- unlist(lapply(lapply(alabama_climbs, unlist), as.character))
all_alabama_routes
```


# CSS Selector Functions
```{r}
scrapeName <- function(x) {
  options(timeout= 4000000)
  climbName <- str_trim(html_text(html_node(read_html(x), 'h1')))
  return(climbName)
}

scrapeGrade <- function(x) {
  options(timeout= 4000000)
  climbGrade <-  
    html_text(html_node(read_html(x), '.mr-2'))
  return(climbGrade)
} 

scrapeDesc <- function (x) {
  options(timeout= 4000000)
  climbDesc <- html_text(html_node(read_html(x), '.max-height-xs-600:nth-child(1) .fr-view'))
  return(climbDesc)
}

scrapeBeta <- function (x) {
  options(timeout= 4000000)
  climbBeta <- html_text(html_node(read_html(x), '.max-height-xs-600:nth-child(2) .fr-view'))
  return(climbBeta)
}

scrapePro <- function (x) {
  options(timeout= 4000000)
  climbPro <- html_text(html_node(read_html(x), '.max-height-xs-600~ .max-height-xs-600+ .max-height-xs-600 .fr-view'))
  return(climbPro)
}

scrapeFA <- function(x) {
  options(timeout= 4000000)
  climbFA <- html_text(html_node(read_html(x), '.description-details tr:nth-child(2) td+ td'))
  climbFA <- gsub("\n","",climbFA)
  climbFA <- str_trim(climbFA)
  return(climbFA)
}

scrapeTicks <- function(x) {
  options(timeout= 4000000)
  climbTicks <- html_text(html_node(read_html(x), '.col-sm-8 .text-muted'))
  return(climbTicks)
}

scrapeRating <- function(x) {
  options(timeout= 4000000)
  climbRating <- str_trim(gsub("\n", "", html_text(html_node(read_html(x), '#route-star-avg span')))) 
  return(climbRating)
}

```

```{r}
getSuggGradeTable<- function(x) {
  tables <- html_table(html_nodes(read_html(x), "table"))
  df <- bind_rows(tables)
  df <- filter(df, !is.na(X2))
  suggested_grades <- df[!grepl("\\,",df$X2),]
  return(suggested_grades)
}

getCommentTable<- function(x) {
  tables <- html_table(html_nodes(read_html(x), "table"))
  df <- bind_rows(tables)
  df <- filter(df, !is.na(X2))
  tick_comments <- df[grepl("\\,",df$X2),]
  return(tick_comments)
}

```



```{r}
scrapeLinks <- function(url){
  options(timeout= 4000000)
  # Create an html document from the url
  webpage <- xml2::read_html(url)
  # Extract the URLs
  url_ <- webpage %>%
    html_nodes("a") %>%
    html_attr("href")
  # Extract the link text
  link_ <- webpage %>%
    html_nodes("a") %>%
    html_text()
  return(data_frame(link = link_, url = url_))
}

getClimbData <- function(x,y) {
  options(timeout= 4000000)
  x <- as.character(x)
  y <- as.character(y)
  names <- sapply(x, scrapeName)
  grades <- sapply(x, scrapeGrade)
  fas <- sapply(x, scrapeFA)
  descs <- sapply(x, scrapeDesc)
  beta <- sapply(x, scrapeBeta)
  pro <- sapply(x, scrapePro)
  ticks <- sapply(y, scrapeTicks)
  ratings <- sapply(y, scrapeRating)
  df <- data.frame("names" = names, 
                   "grades" = grades, 
                   "FA" = fas, 
                   "descriptions" = descs,
                   "beta" = beta,
                   "protection" = pro, 
                   "ticks" = ticks, 
                   "ratings" = ratings, 
                   row.names = NULL)
  return(df)
}

getAllComments <- function(stats, climb_names) {
  options(timeout= 4000000)
  stats <- as.character(stats)
  listOfTables <- lapply(stats, getCommentTable)
  try(
    for (i in 1:length(listOfTables)) {
      listOfTables[[i]]$climb_name <- climb_names[i]
    }, silent = TRUE)
  out <- bind_rows(listOfTables)
  return(out)
}

getAllSuggestedGrades <- function(stats, climb_names) {
  options(timeout = 4000000)
  stats <- as.character(stats)
  listOfTables <- lapply(stats, getSuggGradeTable)
  try(
    for (i in 1:length(listOfTables)) {
      listOfTables[[i]]$climb_name <- climb_names[i]
    }, silent = TRUE)
  out <- bind_rows(listOfTables)
  return(out)
}
```


Gets Route Links and Stats Links for Given query
```{r}
mp_scraper <- function(x) {
  options(timeout= 4000000)
  all_links <- scrapeLinks(x)
  route_links <- filter(all_links, grepl("/route/", url))
  route_urls <- as.character(unique(route_links$url))
  stat_urls <- as.character(gsub("/route/", "/route/stats/", route_urls))
  climb_df <- getClimbData(route_urls, stat_urls)
  comment_df <- getAllComments(stat_urls, climb_df$name)
  sugg_grade_df <- getAllSuggestedGrades(stat_urls, climb_df$name)
  all_tables <- list(climb_df,comment_df, sugg_grade_df)
  return(all_tables)
}
test <- mp_scraper(storm_boulder_url)

test_climb <- test[[1]]
test_comment <- test[[2]]
test_sugg_grade <- test [[3]]
```



# Cleaning
```{r}

sb_clean <- read.csv("storm_boulders_data_raw.csv")
sb_clean <- select(sb_clean, -X)
sb_splitratings <- str_split(sb_clean$ratings, " ")
sb_clean$avg.rating <- as.numeric(unlist(lapply(sb_splitratings, `[`, 2)))
sb_clean$votes <- as.numeric(unlist(lapply(sb_splitratings, `[`, 4)))
sb_clean <- select(sb_clean, -ratings)

sb_clean$grades <- gsub("V", "", sb_clean$grades)
sb_clean$grades <- as.character(unlist(lapply(str_split(sb_clean$grades, "\\+|\\-|/| "), `[`,1)))



sb_clean$ticks[is.na(sb_clean$ticks)] <- 0
```

